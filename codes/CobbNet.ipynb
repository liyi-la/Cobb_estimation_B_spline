{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\10298\\AppData\\Local\\anaconda3\\envs\\pytorch\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import os\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "import csv\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from B_spline import BS_curve\n",
    "from utils import keyP,cobb_angle_line\n",
    "path_heatmap=r'D:\\Project\\Xiehe_Spinal_image_stitching\\cobb\\Heatmap'\n",
    "path_image=r'D:\\Project\\Xiehe_Spinal_image_stitching\\cobb\\ke30_u7_AASCE2019-master\\boostnet_labeldata'\n",
    "class CobbNetDataset(Dataset):\n",
    "    def __init__(self, path,path_heatmap, train=True):\n",
    "        self.names = []\n",
    "        self.labels = []\n",
    "        self.cobb_angles=[]\n",
    "        self.heatmap_names=[]\n",
    "        self.scale=4#heatmap的缩放倍数\n",
    "        self.train=train\n",
    "        if train:\n",
    "            image_path = path + \"/data/training_preprocessed/\"  # 原图\n",
    "            heatmaps_path = path_heatmap+\"/pred_training_cp/\"   # 对应的热图\n",
    "            names = csv.reader(open(path + \"/labels/training/filenames.csv\", 'r'))  # 文件名\n",
    "            cobb_angles= csv.reader(open(path + \"/labels/training/angles.csv\", 'r')) # 对应的cobb角\n",
    "            names=list(names)\n",
    "            self.names=[image_path+n[0] for n in names]\n",
    "            self.heatmap_names=[heatmaps_path+n[0] for n in names]\n",
    "            landmarks = csv.reader(open(path + \"/labels/training/landmarks.csv\", 'r'))\n",
    "        else:\n",
    "            image_path = path + \"/data/test/\"\n",
    "            heatmaps_path = path_heatmap+\"/pred_test_cp/\"\n",
    "            names = csv.reader(open(path + \"/labels/test/filenames.csv\", 'r'))\n",
    "            cobb_angles= csv.reader(open(path + \"/labels/test/angles.csv\", 'r'))\n",
    "            names=list(names)\n",
    "            self.names=[image_path+n[0] for n in names]\n",
    "            self.heatmap_names=[heatmaps_path+n[0] for n in names]\n",
    "            landmarks = csv.reader(open(path + \"/labels/test/landmarks.csv\", 'r'))\n",
    "        \n",
    "        for landmark_each_image in landmarks:  # 地标\n",
    "            coordinate_list = []\n",
    "            for coordinate in landmark_each_image:\n",
    "                coordinate_list.append(float(coordinate))\n",
    "            self.labels.append(coordinate_list)\n",
    "            \n",
    "        for cobb_each in cobb_angles:  # cobb角\n",
    "            cobb_list = []\n",
    "            for cobb in cobb_each:\n",
    "                cobb_list.append(float(cobb))\n",
    "            self.cobb_angles.append(cobb_list)\n",
    "             \n",
    "\n",
    "    def pad_img(self, img, flag=True): \n",
    "          \n",
    "        h,w=img.shape[:2]\n",
    "        if(flag):\n",
    "            h_max=3840\n",
    "            w_max=1536\n",
    "        else:\n",
    "            h_max=960\n",
    "            w_max=384\n",
    "        top = math.floor((h_max - h)/2)\n",
    "        bottom = round((h_max - h)/2+0.1)\n",
    "        left = math.floor((w_max - w) / 2)\n",
    "        right = round((w_max - w) / 2+0.1)#四舍五入\n",
    "        image_padded = cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT, value=(0, 0, 0))\n",
    "        \n",
    "        return image_padded\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_name = self.names[index]\n",
    "        label = self.labels[index]\n",
    "        cobb_angle_GT=np.array(self.cobb_angles[index])\n",
    "\n",
    "        heatmap_name=self.heatmap_names[index]\n",
    "        origin_image = cv2.imread(image_name)\n",
    "        image_padded=self.pad_img(origin_image)\n",
    "\n",
    "        target_height = image_padded.shape[0]//4 # 3840/4=960 缩小原图输入\n",
    "        target_width =image_padded.shape[1]//4 # 1536/4=384\n",
    "        image_resize=cv2.resize(image_padded, (target_width, target_height))#结果存在image\n",
    "        heatmap = cv2.imread(heatmap_name,0)\n",
    "        heatmap_padded=self.pad_img(heatmap,False)\n",
    "        kp = keyP(heatmap)\n",
    "        heatmap_y=[coord[0] for coord in kp]\n",
    "        heatmap_x=[coord[1] for coord in kp]\n",
    "        bs=BS_curve(9,3)  #10个控制点，3次B样条\n",
    "        kp_pred = np.array([heatmap_y,heatmap_x]).T # 基于热图计算B样条参数\n",
    "        paras = bs.estimate_parameters(kp_pred) # B样条参数\n",
    "        knots = bs.get_knots() # 节点\n",
    "        if bs.check():\n",
    "            cp = bs.approximation(kp_pred) # 控制点\n",
    "        uq = np.linspace(0,1,34)\n",
    "        y_c = np.array(bs.bs(uq)) # 计算B样条曲线\n",
    "        cobb_angle=np.array(cobb_angle_line(y_c)) # 基于预测的中心点计算角度\n",
    "        xs=[]\n",
    "        ys=[]\n",
    "        p=label\n",
    "        img_src_resize=cv2.resize(origin_image, (target_width, target_height))\n",
    "        h,w=img_src_resize.shape[:2]\n",
    "        num_p = len(p)//2\n",
    "        for i in range(0,num_p,2):\n",
    "            xs.append((p[i]+p[i+1])*w/2) # 原图像脊柱中心点\n",
    "            ys.append((p[i+num_p]+p[i+num_p+1])*h/2)\n",
    "\n",
    "        bs=BS_curve(9,3) # 10个控制点，3次B样条\n",
    "        kp_GT = np.array([ys,xs]).T # 基于GT控制点计算B样条参数\n",
    "        paras_GT = bs.estimate_parameters(kp_GT)\n",
    "        knots_GT = bs.get_knots()\n",
    "        if bs.check():\n",
    "            cp_GT = bs.approximation(kp_GT)\n",
    "\n",
    " \n",
    "        # heatmap_resize=cv2.resize(heatmap_padded ,(target_width//self.scale,target_height//self.scale)) #960/4=240 ,384/4=96缩小heatmap输入\n",
    "        \n",
    "        image_resize = torch.tensor(image_resize, dtype=torch.float32)\n",
    "        heatmap = torch.tensor(heatmap, dtype=torch.float32)\n",
    "\n",
    "        \n",
    "        return origin_image.shape,image_resize,label,heatmap_padded,image_name,kp_pred,cp,knots,cp_GT,knots_GT,cobb_angle,cobb_angle_GT\n",
    "\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeypointBSplineNet(nn.Module):\n",
    "    \"\"\"\n",
    "    基于关键点的B样条Cobb角测量网络\n",
    "    输入：关键点坐标 (data_pred)\n",
    "    输出：控制点 (cp) 和节点 (knots)\n",
    "    通过B样条解析计算Cobb角\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_keypoints=34, num_control_points=10, degree=3, num_angles=4):\n",
    "        super(KeypointBSplineNet, self).__init__()\n",
    "        self.num_keypoints = num_keypoints\n",
    "        self.num_control_points = num_control_points\n",
    "        self.degree = degree\n",
    "        self.num_angles = num_angles\n",
    "        \n",
    "        # 输入维度：num_keypoints * 2 (x, y坐标)\n",
    "        input_dim = num_keypoints * 2\n",
    "        \n",
    "        # 控制点输出维度：num_control_points * 2 (x, y坐标)\n",
    "        cp_output_dim = num_control_points * 2\n",
    "        \n",
    "        # 节点输出维度：num_control_points + degree + 1\n",
    "        knots_output_dim = num_control_points + degree + 1\n",
    "        \n",
    "        # 共享特征提取层\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "        \n",
    "        # 控制点预测头\n",
    "        self.cp_head = nn.Sequential(\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, cp_output_dim)\n",
    "        )\n",
    "        \n",
    "        # 节点预测头\n",
    "        self.knots_head = nn.Sequential(\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, knots_output_dim),\n",
    "            nn.Sigmoid()  # 确保节点值在[0,1]范围内\n",
    "        )\n",
    "        \n",
    "        # B样条处理器\n",
    "        self.bspline_processor = BSplineProcessor(num_control_points, degree)\n",
    "    \n",
    "    def forward(self, keypoints):\n",
    "        \"\"\"\n",
    "        前向传播\n",
    "        Args:\n",
    "            keypoints: 关键点坐标 [B, num_keypoints, 2] 或 [B, num_keypoints*2]\n",
    "        Returns:\n",
    "            cp: 预测的控制点 [B, num_control_points, 2]\n",
    "            knots: 预测的节点 [B, num_control_points + degree + 1]\n",
    "            cobb_angles: 计算的Cobb角 [B, num_angles]\n",
    "        \"\"\"\n",
    "        batch_size = keypoints.shape[0]\n",
    "        \n",
    "        # 确保输入是2D的\n",
    "        if keypoints.dim() == 3:\n",
    "            keypoints = keypoints.view(batch_size, -1)  # [B, num_keypoints*2]\n",
    "        \n",
    "        # 特征提取\n",
    "        features = self.feature_extractor(keypoints)  # [B, 256]\n",
    "        \n",
    "        # 预测控制点\n",
    "        cp_flat = self.cp_head(features)  # [B, num_control_points*2]\n",
    "        cp = cp_flat.view(batch_size, self.num_control_points, 2)  # [B, num_control_points, 2]\n",
    "        \n",
    "        # 预测节点\n",
    "        knots = self.knots_head(features)  # [B, num_control_points + degree + 1]\n",
    "        \n",
    "        # 计算Cobb角\n",
    "        cobb_angles = self._compute_cobb_angles(keypoints, cp, knots)\n",
    "        \n",
    "        return cp, knots, cobb_angles\n",
    "    \n",
    "    def _compute_cobb_angles(self, keypoints, cp, knots):\n",
    "        \"\"\"\n",
    "        通过B样条计算Cobb角\n",
    "        Args:\n",
    "            keypoints: 原始关键点 [B, num_keypoints*2]\n",
    "            cp: 控制点 [B, num_control_points, 2]\n",
    "            knots: 节点 [B, num_control_points + degree + 1]\n",
    "        Returns:\n",
    "            cobb_angles: Cobb角 [B, num_angles]\n",
    "        \"\"\"\n",
    "        batch_size = cp.shape[0]\n",
    "        cobb_angles_list = []\n",
    "        \n",
    "        for b in range(batch_size):\n",
    "            try:\n",
    "                # 创建B样条对象\n",
    "                bs = BS_curve(self.num_control_points - 1, self.degree)\n",
    "                bs.cp = cp[b].detach().cpu().numpy()\n",
    "                bs.u = knots[b].detach().cpu().numpy()\n",
    "                bs.m = knots.shape[1] - 1\n",
    "                \n",
    "                # 检查B样条是否有效\n",
    "                if bs.check():\n",
    "                    # 采样34个点\n",
    "                    uq = np.linspace(0, 1, 34)\n",
    "                    curve_points = np.array(bs.bs(uq))  # [34, 2]\n",
    "                    \n",
    "                    # 计算Cobb角\n",
    "                    cobb_angle = np.array(cobb_angle_line(curve_points))\n",
    "                    cobb_angles_list.append(cobb_angle)\n",
    "                else:\n",
    "                    # 如果B样条无效，返回零角度\n",
    "                    cobb_angles_list.append(np.zeros(self.num_angles))\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"B样条计算错误: {e}\")\n",
    "                cobb_angles_list.append(np.zeros(self.num_angles))\n",
    "        \n",
    "        return torch.tensor(np.array(cobb_angles_list), dtype=torch.float32, device=cp.device)\n",
    "    \n",
    "    def predict_from_keypoints(self, keypoints):\n",
    "        \"\"\"\n",
    "        从关键点预测Cobb角（推理模式）\n",
    "        Args:\n",
    "            keypoints: 关键点坐标 [num_keypoints, 2]\n",
    "        Returns:\n",
    "            cobb_angles: 预测的Cobb角\n",
    "        \"\"\"\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            if keypoints.dim() == 2:\n",
    "                keypoints = keypoints.unsqueeze(0)  # 添加batch维度\n",
    "            \n",
    "            cp, knots, cobb_angles = self.forward(keypoints)\n",
    "            return cobb_angles.squeeze(0)  # 移除batch维度\n",
    "\n",
    "\n",
    "class BSplineProcessor:\n",
    "    \"\"\"B样条处理器\"\"\"\n",
    "    \n",
    "    def __init__(self, num_control_points=10, degree=3):\n",
    "        self.num_control_points = num_control_points\n",
    "        self.degree = degree\n",
    "    \n",
    "    def fit_curve_from_keypoints(self, keypoints):\n",
    "        \"\"\"\n",
    "        从关键点拟合B样条曲线\n",
    "        Args:\n",
    "            keypoints: 关键点坐标 [num_keypoints, 2]\n",
    "        Returns:\n",
    "            bs: B样条对象\n",
    "            cp: 控制点\n",
    "            knots: 节点\n",
    "        \"\"\"\n",
    "        bs = BS_curve(self.num_control_points - 1, self.degree)\n",
    "        data = np.array(keypoints)\n",
    "        paras = bs.estimate_parameters(data)\n",
    "        knots = bs.get_knots()\n",
    "        \n",
    "        if bs.check():\n",
    "            cp = bs.approximation(data)\n",
    "            return bs, cp, knots\n",
    "        else:\n",
    "            return None, None, None\n",
    "\n",
    "\n",
    "class KeypointBSplineLoss(nn.Module):\n",
    "    \"\"\"KeypointBSplineNet的损失函数\"\"\"\n",
    "    \n",
    "    def __init__(self, cp_weight=1.0, knots_weight=1.0, angle_weight=1.0):\n",
    "        super(KeypointBSplineLoss, self).__init__()\n",
    "        self.cp_weight = cp_weight\n",
    "        self.knots_weight = knots_weight\n",
    "        self.angle_weight = angle_weight\n",
    "        self.mse_loss = nn.MSELoss()\n",
    "    \n",
    "    def forward(self, pred_cp, pred_knots, pred_angles, \n",
    "                gt_cp, gt_knots, gt_angles):\n",
    "        \"\"\"\n",
    "        计算总损失\n",
    "        Args:\n",
    "            pred_cp: 预测控制点 [B, num_control_points, 2]\n",
    "            pred_knots: 预测节点 [B, num_control_points + degree + 1]\n",
    "            pred_angles: 预测角度 [B, num_angles]\n",
    "            gt_cp: 真实控制点 [B, num_control_points, 2]\n",
    "            gt_knots: 真实节点 [B, num_control_points + degree + 1]\n",
    "            gt_angles: 真实角度 [B, num_angles]\n",
    "        Returns:\n",
    "            total_loss: 总损失\n",
    "            loss_dict: 各项损失详情\n",
    "        \"\"\"\n",
    "        # 控制点损失\n",
    "        cp_loss = self.mse_loss(pred_cp, gt_cp)\n",
    "        \n",
    "        # 节点损失\n",
    "        knots_loss = self.mse_loss(pred_knots, gt_knots)\n",
    "        \n",
    "        # 角度损失\n",
    "        angle_loss = self.mse_loss(pred_angles, gt_angles)\n",
    "        \n",
    "        # 总损失\n",
    "        total_loss = (self.cp_weight * cp_loss + \n",
    "                     self.knots_weight * knots_loss + \n",
    "                     self.angle_weight * angle_loss)\n",
    "        \n",
    "        loss_dict = {\n",
    "            'total_loss': total_loss.item(),\n",
    "            'cp_loss': cp_loss.item(),\n",
    "            'knots_loss': knots_loss.item(),\n",
    "            'angle_loss': angle_loss.item()\n",
    "        }\n",
    "        \n",
    "        return total_loss, loss_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([2125, 2364, 1485, 1572]), tensor([ 755, 1078,  505,  525]), tensor([3, 3, 3, 3])]\n",
      "B样条计算错误: zero-size array to reduction operation maximum which has no identity\n",
      "B样条计算错误: zero-size array to reduction operation maximum which has no identity\n",
      "B样条计算错误: zero-size array to reduction operation maximum which has no identity\n",
      "B样条计算错误: zero-size array to reduction operation maximum which has no identity\n",
      "预测控制点形状: torch.Size([4, 10, 2])\n",
      "预测节点形状: torch.Size([4, 14])\n",
      "预测角度形状: torch.Size([4, 4])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (4) must match the size of tensor b (3) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m预测角度形状: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpred_angles\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# 计算损失\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m total_loss, loss_dict \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred_cp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred_knots\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred_angles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mcp_GT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mknots_GT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcobb_angle_GT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m总损失: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_loss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m各项损失: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss_dict\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\10298\\AppData\\Local\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[30], line 205\u001b[0m, in \u001b[0;36mKeypointBSplineLoss.forward\u001b[1;34m(self, pred_cp, pred_knots, pred_angles, gt_cp, gt_knots, gt_angles)\u001b[0m\n\u001b[0;32m    202\u001b[0m knots_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmse_loss(pred_knots, gt_knots)\n\u001b[0;32m    204\u001b[0m \u001b[38;5;66;03m# 角度损失\u001b[39;00m\n\u001b[1;32m--> 205\u001b[0m angle_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmse_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred_angles\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgt_angles\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;66;03m# 总损失\u001b[39;00m\n\u001b[0;32m    208\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcp_weight \u001b[38;5;241m*\u001b[39m cp_loss \u001b[38;5;241m+\u001b[39m \n\u001b[0;32m    209\u001b[0m              \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mknots_weight \u001b[38;5;241m*\u001b[39m knots_loss \u001b[38;5;241m+\u001b[39m \n\u001b[0;32m    210\u001b[0m              \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mangle_weight \u001b[38;5;241m*\u001b[39m angle_loss)\n",
      "File \u001b[1;32mc:\\Users\\10298\\AppData\\Local\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\10298\\AppData\\Local\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\loss.py:530\u001b[0m, in \u001b[0;36mMSELoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    529\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmse_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\10298\\AppData\\Local\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\functional.py:3279\u001b[0m, in \u001b[0;36mmse_loss\u001b[1;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m   3276\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3277\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3279\u001b[0m expanded_input, expanded_target \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3280\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39mmse_loss(expanded_input, expanded_target, _Reduction\u001b[38;5;241m.\u001b[39mget_enum(reduction))\n",
      "File \u001b[1;32mc:\\Users\\10298\\AppData\\Local\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\functional.py:73\u001b[0m, in \u001b[0;36mbroadcast_tensors\u001b[1;34m(*tensors)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function(tensors):\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(broadcast_tensors, tensors, \u001b[38;5;241m*\u001b[39mtensors)\n\u001b[1;32m---> 73\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (4) must match the size of tensor b (3) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "batch_size= 4\n",
    "\n",
    "train_dataset = CobbNetDataset(path_image,path_heatmap,train=True)\n",
    "train_loader = DataLoader(train_dataset,batch_size,shuffle=False,num_workers=0)\n",
    "\n",
    "test_dasaset = CobbNetDataset(path_image,path_heatmap,train=False)\n",
    "test_loader = DataLoader(test_dasaset,1,shuffle=True,num_workers=0)\n",
    "model = KeypointBSplineNet(num_keypoints=34, num_control_points=10, degree=3)\n",
    "\n",
    "# 创建损失函数\n",
    "criterion = KeypointBSplineLoss()\n",
    "    \n",
    "i = 1\n",
    "for origin_shape,image_resize,label,heatmap_padded,image_name,kp_pred,cp,knots,cp_GT,knots_GT,cobb_angle,cobb_angle_GT in train_loader:\n",
    "\n",
    "\n",
    "    # 模拟数据\n",
    "    print(origin_shape)\n",
    "    # 前向传播\n",
    "    pred_cp, pred_knots, pred_angles = model(kp_pred.to(torch.float32))\n",
    "    \n",
    "    print(f\"预测控制点形状: {pred_cp.shape}\")\n",
    "    print(f\"预测节点形状: {pred_knots.shape}\")\n",
    "    print(f\"预测角度形状: {pred_angles.shape}\")\n",
    "    \n",
    "    # 计算损失\n",
    "    total_loss, loss_dict = criterion(pred_cp, pred_knots, pred_angles,\n",
    "                                    cp_GT, knots_GT, cobb_angle_GT)\n",
    "    \n",
    "    print(f\"总损失: {total_loss.item():.4f}\")\n",
    "    print(f\"各项损失: {loss_dict}\")\n",
    "    break\n",
    "\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
